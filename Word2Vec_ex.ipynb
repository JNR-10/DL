{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04ec7cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-02 20:45:46.395876: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "# import os\n",
    "# os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"]=\"true\"\n",
    "\n",
    "\n",
    "tfds.disable_progress_bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d428c5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.12.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f4f3671",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-02 20:46:24.061983: W tensorflow/tsl/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"NOT_FOUND: Could not locate the credentials file.\". Retrieving token from GCE failed with \"FAILED_PRECONDITION: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Could not resolve host: metadata.google.internal\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset 80.23 MiB (download: 80.23 MiB, generated: Unknown size, total: 80.23 MiB) to ./imdb_reviews/plain_text/1.0.0...\u001b[0m\n",
      "\u001b[1mDataset imdb_reviews downloaded and prepared to ./imdb_reviews/plain_text/1.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "dataset, info = tfds.load('imdb_reviews', data_dir='.', with_info=True, as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84ad70f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tfds.core.DatasetInfo(\n",
       "    name='imdb_reviews',\n",
       "    full_name='imdb_reviews/plain_text/1.0.0',\n",
       "    description=\"\"\"\n",
       "    Large Movie Review Dataset. This is a dataset for binary sentiment\n",
       "    classification containing substantially more data than previous benchmark\n",
       "    datasets. We provide a set of 25,000 highly polar movie reviews for training,\n",
       "    and 25,000 for testing. There is additional unlabeled data for use as well.\n",
       "    \"\"\",\n",
       "    config_description=\"\"\"\n",
       "    Plain text\n",
       "    \"\"\",\n",
       "    homepage='http://ai.stanford.edu/~amaas/data/sentiment/',\n",
       "    data_path=PosixGPath('/var/folders/rt/b52hl6m156v31p92cyz2vsp80000gn/T/tmpulwa2ag6tfds'),\n",
       "    file_format=tfrecord,\n",
       "    download_size=80.23 MiB,\n",
       "    dataset_size=129.83 MiB,\n",
       "    features=FeaturesDict({\n",
       "        'label': ClassLabel(shape=(), dtype=int64, num_classes=2),\n",
       "        'text': Text(shape=(), dtype=string),\n",
       "    }),\n",
       "    supervised_keys=('text', 'label'),\n",
       "    disable_shuffling=False,\n",
       "    splits={\n",
       "        'test': <SplitInfo num_examples=25000, num_shards=1>,\n",
       "        'train': <SplitInfo num_examples=25000, num_shards=1>,\n",
       "        'unsupervised': <SplitInfo num_examples=50000, num_shards=1>,\n",
       "    },\n",
       "    citation=\"\"\"@InProceedings{maas-EtAl:2011:ACL-HLT2011,\n",
       "      author    = {Maas, Andrew L.  and  Daly, Raymond E.  and  Pham, Peter T.  and  Huang, Dan  and  Ng, Andrew Y.  and  Potts, Christopher},\n",
       "      title     = {Learning Word Vectors for Sentiment Analysis},\n",
       "      booktitle = {Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies},\n",
       "      month     = {June},\n",
       "      year      = {2011},\n",
       "      address   = {Portland, Oregon, USA},\n",
       "      publisher = {Association for Computational Linguistics},\n",
       "      pages     = {142--150},\n",
       "      url       = {http://www.aclweb.org/anthology/P11-1015}\n",
       "    }\"\"\",\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f70c4f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Split('train'): <_PrefetchDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>,\n",
       " Split('test'): <_PrefetchDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>,\n",
       " Split('unsupervised'): <_PrefetchDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d158b2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = dataset['train'], dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e13d19b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.prefetch_op._PrefetchDataset"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d3d0cdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f68dc2b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34796a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-02 20:48:56.728198: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_3' with dtype int64 and shape [1]\n",
      "\t [[{{node Placeholder/_3}}]]\n",
      "2023-06-02 20:48:56.729618: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int64 and shape [1]\n",
      "\t [[{{node Placeholder/_4}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\"This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it.\"\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-02 20:48:56.934889: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "for sample in train_dataset:\n",
    "    print(sample[0].numpy())\n",
    "    print(sample[1].numpy())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a992fa0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22e80851",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96c1dfae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-02 20:49:19.310461: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-02 20:49:19.311897: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype string and shape [1]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "texts:  [b\"I liked the movie, first of all because it told an interesting story, but the story as told in the movie felt like it was condensed from a much-longer story. Since the book is over 400 pages, that makes sense. It spans a time period from the 1920s to the 1970s, in a fictional South American country, also a lot to fit into the time available. I think it would have been much better as a six-hour mini-series than it turned out as a 140-minute movie.<br /><br />Even though it's rushed, the story doesn't skip so much that it gets confusing. What is told is told fairly well. One fault is that Clara's supernatural powers appear inconsistently; either they should have appeared more evenly through the course of the movie, or they should have been left out. Two more faults (which could be spoilers): Esteban's eventual return to goodness happens somewhat too suddenly, and Ferula's curse seems to wear off, even though the tone of the story suggests that it should endure forever.<br /><br />The acting is excellent. Glenn Close, as the tormented spinster Ferula, is outstanding. Jeremy Irons, as the brutal self-made rich man, is also excellent. Meryl Streep, as the main character Clara, is great, although she's often even better than she was in this movie. There were many well-performed smaller roles too. The biggest fault is that the movie seemed to lack a dialect coach; each actor seemed to speak in a different sort of accent.\"\n",
      " b\"Luise Rainer received an Oscar for her performance in The Good Earth. Unfortunately, her role required no. She did not say much and looked pale throughout the film. Luise's character was a slave then given away to marriage to Paul Muni's character (he did a fantastic job for his performance). Set in ancient Asia, both actors were not Asian, but were very convincing in their roles. I hope that Paul Muni received an Oscar for his performance, because that is what Luise must have gotten her Oscar for. She must have been a breakthrough actress, one of the first to method act. This seems like something that Hollywood does often. Al Pacino has played an Italian and Cuban. I felt Luise's performance to be lackluster throughout, and when she died, she did not change in expression from any previous scenes. She stayed the same throughout the film; she only changed her expression or emotion maybe twice. If her brilliant acting was so subtle, I suppose I did not see it.\"\n",
      " b\"The only redeeming quality of this overlong miscast melodrama is the scenery of southern France and the voice of Nana Mascouri singing the theme song. Stephanie Powers is miscast and betrayed by a phony accent. As has been pointed out, she is too old to play an 18 year old and looks far too young as a grandmother with a college age granddaughter? Lee Remick is good although she also is ageless in her later years. The talented Joanna Lumley is under utilized and also manages to look forever young when her middle aged son (Robert Urich) finally marries Grandma Stephanie Powers. Stacey Keach's ceaseless arrogance makes you wonder what these women saw in him. Don't know how any viewer could relate to his excessive portrayal? The most credible performance is given by Ian Richardson, who makes the rest of the cast look like rank amateurs. It strains credulity that the handsome male suitors in this epic would remain ever single while they patiently await the subject of their affections to finally consent to accept them. Can anybody believe that handsome Robert Urich would remain single for decades waiting for Stephanie Powers to finally accept his endless marriage proposals? The WW2 engagement between the Wehrmacht and the Marquis is laughable. To begin with, the Germans did not occupy the Provence section of France until late in the war, it was controlled by the Vichy French puppet government. We see the French resistance staging a daylight raid on Mistral's villa to steal sheets after which they all lounge under a bridge waiting for a lumbering truckload of Nazi troops to surprise and annihilate them? If you want to see a well acted mini-series set in a foreign country, don't watch Mistral's Daughter. A far better alternative would be The Thorn Birds.\"]\n",
      "\n",
      "labels:  [1 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-02 20:49:19.793803: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "for example, label in train_dataset.take(1):\n",
    "    print('texts: ', example.numpy()[:3])\n",
    "    print()\n",
    "    print('labels: ', label.numpy()[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "404f01ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = tf.keras.layers.experimental.preprocessing.TextVectorization()\n",
    "e.adapt([\n",
    "    \"I love samosas and jalebi\",\n",
    "    \"I love biking and yoga\",\n",
    "    \"I love tensorflow\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d803bbfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '[UNK]',\n",
       " 'love',\n",
       " 'i',\n",
       " 'and',\n",
       " 'yoga',\n",
       " 'tensorflow',\n",
       " 'samosas',\n",
       " 'jalebi',\n",
       " 'biking']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e311763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 2, 1]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e([\"I love pizza\"]).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14ac58e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-02 20:49:45.697620: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype string and shape [1]\n",
      "\t [[{{node Placeholder/_2}}]]\n",
      "2023-06-02 20:49:45.699775: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype string and shape [1]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    }
   ],
   "source": [
    "VOCAB_SIZE = 1000\n",
    "encoder = tf.keras.layers.experimental.preprocessing.TextVectorization(\n",
    "    max_tokens=VOCAB_SIZE)\n",
    "encoder.adapt(train_dataset.map(lambda text, label: text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5672e615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', '[UNK]', 'the', 'and', 'a', 'of', 'to', 'is', 'in', 'it', 'i',\n",
       "       'this', 'that', 'br', 'was', 'as', 'for', 'with', 'movie', 'but',\n",
       "       'film', 'on', 'not', 'you', 'are'], dtype='<U14')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = np.array(encoder.get_vocabulary())\n",
    "vocab[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d7e75fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=string, numpy=\n",
       "array([b\"I liked the movie, first of all because it told an interesting story, but the story as told in the movie felt like it was condensed from a much-longer story. Since the book is over 400 pages, that makes sense. It spans a time period from the 1920s to the 1970s, in a fictional South American country, also a lot to fit into the time available. I think it would have been much better as a six-hour mini-series than it turned out as a 140-minute movie.<br /><br />Even though it's rushed, the story doesn't skip so much that it gets confusing. What is told is told fairly well. One fault is that Clara's supernatural powers appear inconsistently; either they should have appeared more evenly through the course of the movie, or they should have been left out. Two more faults (which could be spoilers): Esteban's eventual return to goodness happens somewhat too suddenly, and Ferula's curse seems to wear off, even though the tone of the story suggests that it should endure forever.<br /><br />The acting is excellent. Glenn Close, as the tormented spinster Ferula, is outstanding. Jeremy Irons, as the brutal self-made rich man, is also excellent. Meryl Streep, as the main character Clara, is great, although she's often even better than she was in this movie. There were many well-performed smaller roles too. The biggest fault is that the movie seemed to lack a dialect coach; each actor seemed to speak in a different sort of accent.\",\n",
       "       b\"Luise Rainer received an Oscar for her performance in The Good Earth. Unfortunately, her role required no. She did not say much and looked pale throughout the film. Luise's character was a slave then given away to marriage to Paul Muni's character (he did a fantastic job for his performance). Set in ancient Asia, both actors were not Asian, but were very convincing in their roles. I hope that Paul Muni received an Oscar for his performance, because that is what Luise must have gotten her Oscar for. She must have been a breakthrough actress, one of the first to method act. This seems like something that Hollywood does often. Al Pacino has played an Italian and Cuban. I felt Luise's performance to be lackluster throughout, and when she died, she did not change in expression from any previous scenes. She stayed the same throughout the film; she only changed her expression or emotion maybe twice. If her brilliant acting was so subtle, I suppose I did not see it.\"],\n",
       "      dtype=object)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aeb967de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 10, 405,   2, ...,   0,   0,   0],\n",
       "       [  1,   1,   1, ...,   0,   0,   0],\n",
       "       [  2,  61,   1, ...,   0,   0,   0]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_example = encoder(example)[:3].numpy()\n",
    "encoded_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5fa301b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  b\"I liked the movie, first of all because it told an interesting story, but the story as told in the movie felt like it was condensed from a much-longer story. Since the book is over 400 pages, that makes sense. It spans a time period from the 1920s to the 1970s, in a fictional South American country, also a lot to fit into the time available. I think it would have been much better as a six-hour mini-series than it turned out as a 140-minute movie.<br /><br />Even though it's rushed, the story doesn't skip so much that it gets confusing. What is told is told fairly well. One fault is that Clara's supernatural powers appear inconsistently; either they should have appeared more evenly through the course of the movie, or they should have been left out. Two more faults (which could be spoilers): Esteban's eventual return to goodness happens somewhat too suddenly, and Ferula's curse seems to wear off, even though the tone of the story suggests that it should endure forever.<br /><br />The acting is excellent. Glenn Close, as the tormented spinster Ferula, is outstanding. Jeremy Irons, as the brutal self-made rich man, is also excellent. Meryl Streep, as the main character Clara, is great, although she's often even better than she was in this movie. There were many well-performed smaller roles too. The biggest fault is that the movie seemed to lack a dialect coach; each actor seemed to speak in a different sort of accent.\"\n",
      "Round-trip:  i liked the movie first of all because it told an interesting story but the story as told in the movie felt like it was [UNK] from a [UNK] story since the book is over [UNK] [UNK] that makes sense it [UNK] a time period from the [UNK] to the [UNK] in a [UNK] [UNK] american country also a lot to [UNK] into the time [UNK] i think it would have been much better as a [UNK] [UNK] than it turned out as a [UNK] moviebr br even though its [UNK] the story doesnt [UNK] so much that it gets [UNK] what is told is told fairly well one [UNK] is that [UNK] [UNK] [UNK] appear [UNK] either they should have [UNK] more [UNK] through the course of the movie or they should have been left out two more [UNK] which could be [UNK] [UNK] [UNK] return to [UNK] happens somewhat too [UNK] and [UNK] [UNK] seems to [UNK] off even though the [UNK] of the story [UNK] that it should [UNK] [UNK] br the acting is excellent [UNK] close as the [UNK] [UNK] [UNK] is [UNK] [UNK] [UNK] as the [UNK] [UNK] [UNK] man is also excellent [UNK] [UNK] as the main character [UNK] is great although shes often even better than she was in this movie there were many [UNK] [UNK] roles too the [UNK] [UNK] is that the movie seemed to lack a [UNK] [UNK] each actor seemed to [UNK] in a different sort of [UNK]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
      "\n",
      "Original:  b\"Luise Rainer received an Oscar for her performance in The Good Earth. Unfortunately, her role required no. She did not say much and looked pale throughout the film. Luise's character was a slave then given away to marriage to Paul Muni's character (he did a fantastic job for his performance). Set in ancient Asia, both actors were not Asian, but were very convincing in their roles. I hope that Paul Muni received an Oscar for his performance, because that is what Luise must have gotten her Oscar for. She must have been a breakthrough actress, one of the first to method act. This seems like something that Hollywood does often. Al Pacino has played an Italian and Cuban. I felt Luise's performance to be lackluster throughout, and when she died, she did not change in expression from any previous scenes. She stayed the same throughout the film; she only changed her expression or emotion maybe twice. If her brilliant acting was so subtle, I suppose I did not see it.\"\n",
      "Round-trip:  [UNK] [UNK] [UNK] an oscar for her performance in the good earth unfortunately her role [UNK] no she did not say much and looked [UNK] throughout the film [UNK] character was a [UNK] then given away to [UNK] to paul [UNK] character he did a fantastic job for his performance set in [UNK] [UNK] both actors were not [UNK] but were very [UNK] in their roles i hope that paul [UNK] [UNK] an oscar for his performance because that is what [UNK] must have [UNK] her oscar for she must have been a [UNK] actress one of the first to [UNK] act this seems like something that hollywood does often [UNK] [UNK] has played an [UNK] and [UNK] i felt [UNK] performance to be [UNK] throughout and when she [UNK] she did not change in [UNK] from any previous scenes she [UNK] the same throughout the film she only [UNK] her [UNK] or [UNK] maybe [UNK] if her brilliant acting was so [UNK] i [UNK] i did not see it                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
      "\n",
      "Original:  b\"The only redeeming quality of this overlong miscast melodrama is the scenery of southern France and the voice of Nana Mascouri singing the theme song. Stephanie Powers is miscast and betrayed by a phony accent. As has been pointed out, she is too old to play an 18 year old and looks far too young as a grandmother with a college age granddaughter? Lee Remick is good although she also is ageless in her later years. The talented Joanna Lumley is under utilized and also manages to look forever young when her middle aged son (Robert Urich) finally marries Grandma Stephanie Powers. Stacey Keach's ceaseless arrogance makes you wonder what these women saw in him. Don't know how any viewer could relate to his excessive portrayal? The most credible performance is given by Ian Richardson, who makes the rest of the cast look like rank amateurs. It strains credulity that the handsome male suitors in this epic would remain ever single while they patiently await the subject of their affections to finally consent to accept them. Can anybody believe that handsome Robert Urich would remain single for decades waiting for Stephanie Powers to finally accept his endless marriage proposals? The WW2 engagement between the Wehrmacht and the Marquis is laughable. To begin with, the Germans did not occupy the Provence section of France until late in the war, it was controlled by the Vichy French puppet government. We see the French resistance staging a daylight raid on Mistral's villa to steal sheets after which they all lounge under a bridge waiting for a lumbering truckload of Nazi troops to surprise and annihilate them? If you want to see a well acted mini-series set in a foreign country, don't watch Mistral's Daughter. A far better alternative would be The Thorn Birds.\"\n",
      "Round-trip:  the only [UNK] quality of this [UNK] [UNK] [UNK] is the [UNK] of [UNK] [UNK] and the voice of [UNK] [UNK] [UNK] the theme song [UNK] [UNK] is [UNK] and [UNK] by a [UNK] [UNK] as has been [UNK] out she is too old to play an [UNK] year old and looks far too young as a [UNK] with a [UNK] age [UNK] lee [UNK] is good although she also is [UNK] in her later years the [UNK] [UNK] [UNK] is under [UNK] and also manages to look [UNK] young when her middle [UNK] son robert [UNK] finally [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] makes you wonder what these women saw in him dont know how any viewer could [UNK] to his [UNK] [UNK] the most [UNK] performance is given by [UNK] [UNK] who makes the rest of the cast look like [UNK] [UNK] it [UNK] [UNK] that the [UNK] male [UNK] in this [UNK] would [UNK] ever single while they [UNK] [UNK] the subject of their [UNK] to finally [UNK] to [UNK] them can [UNK] believe that [UNK] robert [UNK] would [UNK] single for [UNK] [UNK] for [UNK] [UNK] to finally [UNK] his [UNK] [UNK] [UNK] the [UNK] [UNK] between the [UNK] and the [UNK] is [UNK] to begin with the [UNK] did not [UNK] the [UNK] [UNK] of [UNK] until late in the war it was [UNK] by the [UNK] french [UNK] [UNK] we see the french [UNK] [UNK] a [UNK] [UNK] on [UNK] [UNK] to [UNK] [UNK] after which they all [UNK] under a [UNK] [UNK] for a [UNK] [UNK] of [UNK] [UNK] to surprise and [UNK] them if you want to see a well [UNK] [UNK] set in a [UNK] country dont watch [UNK] daughter a far better [UNK] would be the [UNK] [UNK]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n in range(3):\n",
    "    print(\"Original: \", example[n].numpy())\n",
    "    print(\"Round-trip: \", \" \".join(vocab[encoded_example[n]]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "14236e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    encoder,\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim=len(encoder.get_vocabulary()),\n",
    "        output_dim=64,\n",
    "        # Use masking to handle the variable sequence lengths\n",
    "        mask_zero=True),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4f5e2a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 5s 5s/step\n",
      "[-0.01110726]\n"
     ]
    }
   ],
   "source": [
    "sample_text = ('The movie was cool. The animation and the graphics '\n",
    "               'were out of this world. I would recommend this movie.')\n",
    "sample_text = ('awesome movie, I loved it so much')\n",
    "predictions = model.predict(np.array([sample_text]))\n",
    "print(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "96b8f09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fe48f402",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-02 20:50:59.902369: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype string and shape [1]\n",
      "\t [[{{node Placeholder/_2}}]]\n",
      "2023-06-02 20:50:59.903459: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int64 and shape [1]\n",
      "\t [[{{node Placeholder/_4}}]]\n",
      "2023-06-02 20:51:05.286162: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-06-02 20:51:11.291853: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - ETA: 0s - loss: 0.6369 - accuracy: 0.5721"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-02 20:57:41.274786: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype string and shape [1]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2023-06-02 20:57:41.275348: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_3' with dtype int64 and shape [1]\n",
      "\t [[{{node Placeholder/_3}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "391/391 [==============================] - 412s 1s/step - loss: 0.6369 - accuracy: 0.5721 - val_loss: 0.5471 - val_accuracy: 0.7479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-02 20:57:51.961707: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x143413b10>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataset, epochs=1,\n",
    "                    validation_data=test_dataset,\n",
    "                    validation_steps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7504ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
